{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e356a81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\projects\\stage_gpt\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "import torch\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a9e5c9",
   "metadata": {},
   "source": [
    "# Dataset Download and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb05f696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom datasets import load_dataset\\n\\nds = datasets.load_dataset(\"roneneldan/TinyStories\")\\nds.save_to_disk(\\'datasets_local/tinystories\\')\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download and save dataset\n",
    "\"\"\"\n",
    "from datasets import load_dataset\n",
    "\n",
    "ds = datasets.load_dataset(\"roneneldan/TinyStories\")\n",
    "ds.save_to_disk('datasets_local/tinystories')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88f2dc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_from_disk(\"datasets_local/tinystories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d26ec37",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ac1a634",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sample(index, split='train', display=True, get_text=False):\n",
    "    sample_text = ds[split][index]['text']\n",
    "    encoded_sample = tokenizer.encode(ds['train'][0]['text'], allowed_special={'<|endoftext|>'})\n",
    "\n",
    "    if display:\n",
    "        print(\"=\" * 45)\n",
    "        print(f\"Number of words: {len(sample_text.split(' '))}\")\n",
    "        print(f\"Number of tokens: {len(encoded_sample)}\")\n",
    "        print(\"=\" * 45)    \n",
    "        print(sample_text)\n",
    "        \n",
    "    if get_text:\n",
    "        return (sample_text, encoded_sample)\n",
    "    else:\n",
    "        return (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1149aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================\n",
      "Number of words: 135\n",
      "Number of tokens: 162\n",
      "=============================================\n",
      "Once upon a time, there was a family who loved to go camping. They had a big tent that they would put up in the woods. The mom and dad would work together to make sure the tent was set up just right. \n",
      "\n",
      "One day, they met a very nice man who was very generous. He gave them some food to eat and even helped them fix their tent when it got a hole in it. The family was very happy to have met such a kind man.\n",
      "\n",
      "After they finished camping, the family went home and told all their friends about the generous man they met. They also talked about how they had to work hard to put up their tent, but it was worth it because they had so much fun camping. The end.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_sample(45, split='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e97d2bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================\n",
      "Number of words: 197\n",
      "Number of tokens: 162\n",
      "=============================================\n",
      "Once upon a time, there was a zipping sound in the quiet room. It sounded like someone was playing with something. Two friends, Mel and June, were curious and excited to find out what was making the noise. \n",
      "\n",
      "\"What's that noise?\" asked June.\n",
      "\"I don't know,\" said Mel, \"Let's go find out!\"\n",
      "\n",
      "The two went searching around the room until they found the source of the noise: a pin, zipping up and down the wall!\n",
      "\n",
      "\"How unusual,\" said June, \"How does it zip up and down the wall like that?\n",
      "\n",
      "Mel put her finger to her lips and said, \"Shhh, maybe it's magic?\"\n",
      "\n",
      "June's wide eyes lit up as she said, \"That's it! I think we should try to figure out how it works!\"\n",
      "\n",
      "The two friends worked together to try and make the pin zip again. After a few minutes of hard work, the pin began to zip again!\n",
      "\n",
      "\"Woo-hoo!\" cried Mel, \"We did it! How exciting! I think this pin has a magical zipping power!\"\n",
      "\n",
      "June and Mel enjoyed their newfound discovery and magic pin. From that day forward, the two friends would take turns zipping the pin up and down the wall. It was the quietest, most exciting adventure they ever had.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_sample(124, split='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e7889a",
   "metadata": {},
   "source": [
    "# Deciding Model Parameters based on the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d26dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "1300000\n",
      "1400000\n",
      "1500000\n",
      "1600000\n",
      "1700000\n",
      "1800000\n",
      "1900000\n",
      "2000000\n",
      "2100000\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[49]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m curr_sample % \u001b[32m100000\u001b[39m == \u001b[32m0\u001b[39m:\n\u001b[32m     11\u001b[39m     \u001b[38;5;28mprint\u001b[39m(curr_sample)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[43mtokens\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcurr_sample\u001b[49m\u001b[43m]\u001b[49m = \u001b[38;5;28mlen\u001b[39m(tokenizer.encode(ds[split][i][\u001b[33m'\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m'\u001b[39m]))\n",
      "\u001b[31mIndexError\u001b[39m: list assignment index out of range"
     ]
    }
   ],
   "source": [
    "# 47586\n",
    "# Decide the model parameters\n",
    "\n",
    "total_samples = len(ds['train']) + len(ds['validation'])\n",
    "tokens = [0] * total_samples\n",
    "curr_sample = 0\n",
    "for split in ['train', 'validation']:\n",
    "    for i in range(len(ds[split])):\n",
    "        if curr_sample % 100000 == 0:\n",
    "            print(curr_sample)\n",
    "        tokens[curr_sample] = len(tokenizer.encode(ds[split][i]['text']))\n",
    "        curr_sample += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8a83760a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Tokens:  476616185\n",
      "Mean Length: 222.5401233314143\n",
      "Median:  191.0\n",
      "Percentiles: [   0.  143.  158.  169.  180.  191.  205.  222.  252.  355. 1269.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(\"Total Number of Tokens: \", np.sum(tokens))\n",
    "print(\"Mean Length:\", np.mean(tokens))\n",
    "print(\"Median: \", np.median(tokens))\n",
    "print(\"Percentiles:\", np.percentile(tokens, q = np.arange(0, 101, 10)))\n",
    "\n",
    "_ = plt.hist(tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71904184",
   "metadata": {},
   "source": [
    "Therefore, with context_length of 256, we have the whole story as the context for the next word prediction for >80% of the stories.\n",
    "But, how many a parameters would that be? - It is 44.8M with this config - \n",
    "\n",
    "{'num_layers': 6,\n",
    "  'num_heads': 8,\n",
    "  'd_model': 512,\n",
    "  'd_ff': 2048,\n",
    "  'dropout_rate': 0.1,\n",
    "  'context_length': 512,\n",
    "  'vocab_size': 50257,\n",
    "  'embedding_dim': 512},\n",
    " 'context_length': 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e307be",
   "metadata": {},
   "source": [
    "# Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b04a376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: {'num_layers': 8, 'num_heads': 4, 'd_model': 256, 'd_ff': 1024, 'dropout_rate': 0.1, 'context_length': 256, 'vocab_size': 50257, 'embedding_dim': 256}\n",
      "#Params with the above config: 19.300177 M parameters\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from transformer.transformer import GPTModel\n",
    "\n",
    "with open(\"transformer/sample_config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)['config']\n",
    "\n",
    "config.update({\n",
    "    'context_length': 256,\n",
    "    'd_model': 256,\n",
    "    'embedding_dim': 256,\n",
    "    'num_layers': 8,\n",
    "    'num_heads': 4,\n",
    "    'd_ff': 1024\n",
    "})\n",
    "\n",
    "print(\"Config:\", config)\n",
    "\n",
    "model = GPTModel(config)\n",
    "print(\"#Params with the above config:\", model.get_numel() / 1e6, \"M parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da8a94b",
   "metadata": {},
   "source": [
    "Out of this 19.3M parameters, \n",
    "\n",
    "- Token Embedding accounts for 50527 * 256 = 12.9M parameters. \n",
    "- The rest of the layers are 6.4M parameters.\n",
    "\n",
    "This seems to be expected and explains the fixed cost of representation of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e315f6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the tokenized data into mmap\n",
    "def process(sample):\n",
    "    ids = tokenizer.encode_ordinary(sample['text'])\n",
    "    return {'tokens': ids, 'len': len(ids)}\n",
    "\n",
    "dataset_folder = \"datasets_local/\"\n",
    "tokenized_ds = None\n",
    "if not os.path.exists(os.path.join(dataset_folder, \"train.bin\")):\n",
    "    tokenized_ds = ds.map(\n",
    "        process,\n",
    "        remove_columns=['text'],\n",
    "        num_proc=8,\n",
    "        desc=\"Tokenizing data\"\n",
    "    )\n",
    "\n",
    "    for split, dset in tokenized_ds.items():\n",
    "        total_len = np.sum(dset['len'])\n",
    "        filename = os.path.join(dataset_folder, f\"{split}.bin\")\n",
    "        fp = np.memmap(filename, dtype=np.uint16, mode = \"w+\", shape=(total_len,))\n",
    "        batches = 1024\n",
    "\n",
    "        idx = 0\n",
    "        for i in tqdm(range(batches), desc=\"Saving to disk\"):\n",
    "            batch = dset.shard(num_shards=1024, index=i, contiguous=True).with_format('numpy')\n",
    "            batch_arr = np.concatenate(batch['tokens'])\n",
    "            fp[idx: idx + len(batch_arr)] = batch_arr\n",
    "            idx += len(batch_arr)\n",
    "            fp.flush() # Save each batch to reduce memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11abc728",
   "metadata": {},
   "outputs": [],
   "source": [
    "device =  \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device_type = 'cuda' if 'cuda' in device else 'cpu' # for later use in torch.autocast\n",
    "# note: float16 data type will automatically use a GradScaler\n",
    "\n",
    "# How to use autocast https://wandb.ai/wandb_fc/tips/reports/How-To-Use-Autocast-in-PyTorch--VmlldzoyMTk4NTky\n",
    "dtype = 'bfloat16' if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else 'float16' # 'float32', 'bfloat16', or 'float16', the latter will auto implement a GradScaler\n",
    "ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]\n",
    "\n",
    "ctx = nullcontext() if device_type == 'cpu' else torch.amp.autocast(device_type=device_type, dtype=ptdtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ca619aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(context_size, batch_size, split='train', device='cpu'):\n",
    "    data = np.memmap(os.path.join(dataset_folder, f\"{split}.bin\"), dtype=np.uint16, mode='r')\n",
    "    ix = np.random.randint(low=0, high=len(data) - context_size - 1, size=batch_size)\n",
    "    x = torch.vstack([torch.tensor(data[i:i+context_size]) for i in ix])\n",
    "    y = torch.vstack([torch.tensor(data[i+1:i+1+context_size]) for i in ix])\n",
    "    if device == 'cuda':\n",
    "        x, y = x.pin_memory().to(device, non_blocking=True), y.pin_memory().to(device, non_blocking=True)\n",
    "    return x.long(), y.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d29a1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_loss(model, eval_iters, context_size, batch_size=8, device='cpu'):\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for split in ['train', 'validation']:\n",
    "            losses = torch.zeros(eval_iters)\n",
    "            for i in range(eval_iters):\n",
    "                x, y = get_batch(context_size, batch_size, split=split, device=device)\n",
    "                # with ctx:\n",
    "                _, loss = model(x, y)\n",
    "                losses[i] = loss.item()\n",
    "            out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70363243",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_freq = 100\n",
    "max_iters = 1000\n",
    "eval_iters = 100\n",
    "gradient_accumulation_steps = 32\n",
    "learning_rate = 1e-4\n",
    "min_lr = 5e-5\n",
    "warmup_iters = 1000\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dc3b4a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import LinearLR,SequentialLR, CosineAnnealingLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6853fd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, betas=(0.9, 0.95), eps=1e-8, weight_decay=0.1)\n",
    "\n",
    "scheduler_warmup = LinearLR(optimizer, total_iters=warmup_iters)\n",
    "scheduler_decay = CosineAnnealingLR(optimizer, T_max=max_iters - warmup_iters, eta_min=min_lr)\n",
    "scheduler = SequentialLR(optimizer, [scheduler_warmup, scheduler_decay], milestones=[warmup_iters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "502a421a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_loss = torch.inf\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "best_model_path = \"best_slm_model.pt\"\n",
    "\n",
    "def train(model, optimizer, scheduler, config, device):\n",
    "    best_val_loss = torch.inf\n",
    "    context_size = config['context_length']\n",
    "    for epoch in tqdm(range(max_iters), desc=\"Epochs\"):\n",
    "        if ((epoch + 1) % log_freq) == 0:\n",
    "            curr_loss = estimate_loss(model, eval_iters, context_size, batch_size, device=device)\n",
    "            train_losses.append(curr_loss['train'])\n",
    "            val_losses.append(curr_loss['validation'])\n",
    "            print(f\"Epoch {epoch:3d} - Train Loss {curr_loss['train']:.4f}, Val Loss {curr_loss['validation']:.4f}\")\n",
    "\n",
    "            if curr_loss['validation'] < best_val_loss:\n",
    "                best_val_loss = curr_loss['validation']\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "\n",
    "        x, y = get_batch(context_size, batch_size, split='train', device=device)\n",
    "        logits, loss = model(x, y)\n",
    "        loss = loss / gradient_accumulation_steps\n",
    "        loss.backward()\n",
    "\n",
    "        if ((epoch + 1) % gradient_accumulation_steps == 0) or (epoch + 1 == max_iters):\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e0b728c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  10%|▉         | 99/1000 [00:06<00:53, 16.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  99 - Train Loss 147.1870, Val Loss 147.2832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|█▉        | 199/1000 [00:17<00:46, 17.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199 - Train Loss 138.1514, Val Loss 138.3302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  30%|██▉       | 298/1000 [00:30<00:41, 16.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299 - Train Loss 127.6287, Val Loss 127.7110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 400/1000 [00:47<08:26,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 399 - Train Loss 115.9785, Val Loss 116.0830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  50%|████▉     | 499/1000 [00:53<00:29, 16.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499 - Train Loss 104.0334, Val Loss 104.1917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|█████▉    | 599/1000 [01:04<00:24, 16.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 599 - Train Loss 92.6496, Val Loss 92.8690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  70%|██████▉   | 699/1000 [01:15<00:18, 16.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 699 - Train Loss 82.6958, Val Loss 82.6086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  80%|███████▉  | 799/1000 [01:27<00:12, 16.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 799 - Train Loss 74.3929, Val Loss 74.4179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  90%|████████▉ | 898/1000 [01:38<00:06, 16.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 899 - Train Loss 66.5160, Val Loss 66.5801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|█████████▉| 998/1000 [01:49<00:00, 16.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 999 - Train Loss 62.3631, Val Loss 62.4472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 1000/1000 [01:54<00:00,  8.70it/s]\n"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "train(model, optimizer, scheduler, config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "830c92c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the model\n",
    "model = GPTModel(config)  # re-create the model with same config\n",
    "best_model_params_path = \"best_slm_model.pt\"\n",
    "model.load_state_dict(torch.load(best_model_params_path, map_location=torch.device(device))) # load best model states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8d81405e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time there was a pumpkin.lorelorelorelorelorelorelorelorelorelorelorelorelorelorelorelore\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Once upon a time there was a pumpkin.\"\n",
    "context = (torch.tensor(tokenizer.encode_ordinary(sentence)).unsqueeze(dim = 0)).to(device)\n",
    "y = model.generate(context, 16)\n",
    "print(tokenizer.decode(y.squeeze().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b219061d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
